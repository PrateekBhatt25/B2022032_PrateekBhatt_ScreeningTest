{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df7e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f57b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load algoparams_from_ui JSON file\n",
    "with open(\"sample.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57c3ddcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session_name': 'test',\n",
       " 'session_description': 'test',\n",
       " 'design_state_data': {'session_info': {'project_id': '1',\n",
       "   'experiment_id': 'kkkk-11',\n",
       "   'dataset': 'iris_modified.csv',\n",
       "   'session_name': 'test',\n",
       "   'session_description': 'test'},\n",
       "  'target': {'prediction_type': 'Regression',\n",
       "   'target': 'petal_width',\n",
       "   'type': 'regression',\n",
       "   'partitioning': True},\n",
       "  'train': {'policy': 'Split the dataset',\n",
       "   'time_variable': 'sepal_length',\n",
       "   'sampling_method': 'No sampling(whole data)',\n",
       "   'split': 'Randomly',\n",
       "   'k_fold': False,\n",
       "   'train_ratio': 0,\n",
       "   'random_seed': 0},\n",
       "  'metrics': {'optomize_model_hyperparameters_for': 'AUC',\n",
       "   'optimize_threshold_for': 'F1 Score',\n",
       "   'compute_lift_at': 0,\n",
       "   'cost_matrix_gain_for_true_prediction_true_result': 1,\n",
       "   'cost_matrix_gain_for_true_prediction_false_result': 0,\n",
       "   'cost_matrix_gain_for_false_prediction_true_result': 0,\n",
       "   'cost_matrix_gain_for_false_prediction_false_result': 0},\n",
       "  'feature_handling': {'sepal_length': {'feature_name': 'sepal_length',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'Average of values',\n",
       "     'impute_value': 0}},\n",
       "   'sepal_width': {'feature_name': 'sepal_width',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'custom',\n",
       "     'impute_value': -1}},\n",
       "   'petal_length': {'feature_name': 'petal_length',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'Average of values',\n",
       "     'impute_value': 0}},\n",
       "   'petal_width': {'feature_name': 'petal_width',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'numerical',\n",
       "    'feature_details': {'numerical_handling': 'Keep as regular numerical feature',\n",
       "     'rescaling': 'No rescaling',\n",
       "     'make_derived_feats': False,\n",
       "     'missing_values': 'Impute',\n",
       "     'impute_with': 'custom',\n",
       "     'impute_value': -2}},\n",
       "   'species': {'feature_name': 'species',\n",
       "    'is_selected': True,\n",
       "    'feature_variable_type': 'text',\n",
       "    'feature_details': {'text_handling': 'Tokenize and hash',\n",
       "     'hash_columns': 0}}},\n",
       "  'feature_generation': {'linear_interactions': [['petal_length',\n",
       "     'sepal_width']],\n",
       "   'linear_scalar_type': 'robust',\n",
       "   'polynomial_interactions': ['petal_length/sepal_width',\n",
       "    'petal_width/species'],\n",
       "   'explicit_pairwise_interactions': ['sepal_width/sepal_length',\n",
       "    'petal_width/sepal_length']},\n",
       "  'feature_reduction': {'feature_reduction_method': 'Tree-based',\n",
       "   'num_of_features_to_keep': '4',\n",
       "   'num_of_trees': '5',\n",
       "   'depth_of_trees': '6'},\n",
       "  'hyperparameters': {'stratergy': 'Grid Search',\n",
       "   'shuffle_grid': True,\n",
       "   'random_state': 1,\n",
       "   'max_iterations': 2,\n",
       "   'max_search_time': 3,\n",
       "   'parallelism': 5,\n",
       "   'cross_validation_stratergy': 'Time-based K-fold(with overlap)',\n",
       "   'num_of_folds': 6,\n",
       "   'split_ratio': 0,\n",
       "   'stratified': True},\n",
       "  'weighting_stratergy': {'weighting_stratergy_method': 'Sample weights',\n",
       "   'weighting_stratergy_weight_variable': 'petal_length'},\n",
       "  'probability_calibration': {'probability_calibration_method': 'Sigmoid - Platt Scaling'},\n",
       "  'algorithms': {'RandomForestClassifier': {'model_name': 'Random Forest Classifier',\n",
       "    'is_selected': False,\n",
       "    'min_trees': 10,\n",
       "    'max_trees': 30,\n",
       "    'feature_sampling_statergy': 'Default',\n",
       "    'min_depth': 20,\n",
       "    'max_depth': 30,\n",
       "    'min_samples_per_leaf_min_value': 5,\n",
       "    'min_samples_per_leaf_max_value': 50,\n",
       "    'parallelism': 0},\n",
       "   'RandomForestRegressor': {'model_name': 'Random Forest Regressor',\n",
       "    'is_selected': True,\n",
       "    'min_trees': 10,\n",
       "    'max_trees': 20,\n",
       "    'feature_sampling_statergy': 'Default',\n",
       "    'min_depth': 20,\n",
       "    'max_depth': 25,\n",
       "    'min_samples_per_leaf_min_value': 5,\n",
       "    'min_samples_per_leaf_max_value': 10,\n",
       "    'parallelism': 0},\n",
       "   'GBTClassifier': {'model_name': 'Gradient Boosted Trees',\n",
       "    'is_selected': False,\n",
       "    'num_of_BoostingStages': [67, 89],\n",
       "    'feature_sampling_statergy': 'Fixed number',\n",
       "    'learningRate': [],\n",
       "    'use_deviance': True,\n",
       "    'use_exponential': False,\n",
       "    'fixed_number': 22,\n",
       "    'min_subsample': 1,\n",
       "    'max_subsample': 2,\n",
       "    'min_stepsize': 0.1,\n",
       "    'max_stepsize': 0.5,\n",
       "    'min_iter': 20,\n",
       "    'max_iter': 40,\n",
       "    'min_depth': 5,\n",
       "    'max_depth': 7},\n",
       "   'GBTRegressor': {'model_name': 'Gradient Boosted Trees',\n",
       "    'is_selected': False,\n",
       "    'num_of_BoostingStages': [67, 89],\n",
       "    'feature_sampling_statergy': 'Fixed number',\n",
       "    'use_deviance': True,\n",
       "    'use_exponential': False,\n",
       "    'fixed_number': 22,\n",
       "    'min_subsample': 1,\n",
       "    'max_subsample': 2,\n",
       "    'min_stepsize': 0.1,\n",
       "    'max_stepsize': 0.5,\n",
       "    'min_iter': 20,\n",
       "    'max_iter': 40,\n",
       "    'min_depth': 5,\n",
       "    'max_depth': 7},\n",
       "   'LinearRegression': {'model_name': 'LinearRegression',\n",
       "    'is_selected': False,\n",
       "    'parallelism': 2,\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8,\n",
       "    'min_elasticnet': 0.5,\n",
       "    'max_elasticnet': 0.8},\n",
       "   'LogisticRegression': {'model_name': 'LogisticRegression',\n",
       "    'is_selected': False,\n",
       "    'parallelism': 2,\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8,\n",
       "    'min_elasticnet': 0.5,\n",
       "    'max_elasticnet': 0.8},\n",
       "   'RidgeRegression': {'model_name': 'RidgeRegression',\n",
       "    'is_selected': False,\n",
       "    'regularization_term': 'Specify values to test',\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8},\n",
       "   'LassoRegression': {'model_name': 'Lasso Regression',\n",
       "    'is_selected': False,\n",
       "    'regularization_term': 'Specify values to test',\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8},\n",
       "   'ElasticNetRegression': {'model_name': 'Lasso Regression',\n",
       "    'is_selected': False,\n",
       "    'regularization_term': 'Specify values to test',\n",
       "    'min_iter': 30,\n",
       "    'max_iter': 50,\n",
       "    'min_regparam': 0.5,\n",
       "    'max_regparam': 0.8,\n",
       "    'min_elasticnet': 0.5,\n",
       "    'max_elasticnet': 0.8},\n",
       "   'xg_boost': {'model_name': 'XG Boost',\n",
       "    'is_selected': False,\n",
       "    'use_gradient_boosted_tree': True,\n",
       "    'dart': True,\n",
       "    'tree_method': '',\n",
       "    'random_state': 0,\n",
       "    'max_num_of_trees': 0,\n",
       "    'early_stopping': True,\n",
       "    'early_stopping_rounds': 2,\n",
       "    'max_depth_of_tree': [56, 89],\n",
       "    'learningRate': [89, 76],\n",
       "    'l1_regularization': [77],\n",
       "    'l2_regularization': [78],\n",
       "    'gamma': [68],\n",
       "    'min_child_weight': [67],\n",
       "    'sub_sample': [67],\n",
       "    'col_sample_by_tree': [67],\n",
       "    'replace_missing_values': False,\n",
       "    'parallelism': 0},\n",
       "   'DecisionTreeRegressor': {'model_name': 'Decision Tree',\n",
       "    'is_selected': False,\n",
       "    'min_depth': 4,\n",
       "    'max_depth': 7,\n",
       "    'use_gini': False,\n",
       "    'use_entropy': True,\n",
       "    'min_samples_per_leaf': [12, 6],\n",
       "    'use_best': True,\n",
       "    'use_random': True},\n",
       "   'DecisionTreeClassifier': {'model_name': 'Decision Tree',\n",
       "    'is_selected': False,\n",
       "    'min_depth': 4,\n",
       "    'max_depth': 7,\n",
       "    'use_gini': False,\n",
       "    'use_entropy': True,\n",
       "    'min_samples_per_leaf': [12, 6],\n",
       "    'use_best': True,\n",
       "    'use_random': True},\n",
       "   'SVM': {'model_name': 'Support Vector Machine',\n",
       "    'is_selected': False,\n",
       "    'linear_kernel': True,\n",
       "    'rep_kernel': True,\n",
       "    'polynomial_kernel': True,\n",
       "    'sigmoid_kernel': True,\n",
       "    'c_value': [566, 79],\n",
       "    'auto': True,\n",
       "    'scale': True,\n",
       "    'custom_gamma_values': True,\n",
       "    'tolerance': 7,\n",
       "    'max_iterations': 7},\n",
       "   'SGD': {'model_name': 'Stochastic Gradient Descent',\n",
       "    'is_selected': False,\n",
       "    'use_logistics': True,\n",
       "    'use_modified_hubber_loss': False,\n",
       "    'max_iterations': False,\n",
       "    'tolerance': 56,\n",
       "    'use_l1_regularization': 'on',\n",
       "    'use_l2_regularization': 'on',\n",
       "    'use_elastic_net_regularization': True,\n",
       "    'alpha_value': [79, 56],\n",
       "    'parallelism': 1},\n",
       "   'KNN': {'model_name': 'KNN',\n",
       "    'is_selected': False,\n",
       "    'k_value': [78],\n",
       "    'distance_weighting': True,\n",
       "    'neighbour_finding_algorithm': 'Automatic',\n",
       "    'random_state': 0,\n",
       "    'p_value': 0},\n",
       "   'extra_random_trees': {'model_name': 'Extra Random Trees',\n",
       "    'is_selected': False,\n",
       "    'num_of_trees': [45, 489],\n",
       "    'feature_sampling_statergy': 'Square root and Logarithm',\n",
       "    'max_depth': [12, 45],\n",
       "    'min_samples_per_leaf': [78, 56],\n",
       "    'parallelism': 3},\n",
       "   'neural_network': {'model_name': 'Neural Network',\n",
       "    'is_selected': False,\n",
       "    'hidden_layer_sizes': [67, 89],\n",
       "    'activation': '',\n",
       "    'alpha_value': 0,\n",
       "    'max_iterations': 0,\n",
       "    'convergence_tolerance': 0,\n",
       "    'early_stopping': True,\n",
       "    'solver': 'ADAM',\n",
       "    'shuffle_data': True,\n",
       "    'initial_learning_rate': 0,\n",
       "    'automatic_batching': True,\n",
       "    'beta_1': 0,\n",
       "    'beta_2': 0,\n",
       "    'epsilon': 0,\n",
       "    'power_t': 0,\n",
       "    'momentum': 0,\n",
       "    'use_nesterov_momentum': False}}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c11d98c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['session_name', 'session_description', 'design_state_data'])\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d9eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract target variable\n",
    "target = data['design_state_data']['target']['target']\n",
    "\n",
    "# Extract type of regression to be run\n",
    "reg_type = data['design_state_data']['target']['type']\n",
    "\n",
    "# Extract feature handling parameters\n",
    "feature_handling = data['design_state_data']['feature_handling']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3153a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    # Read feature details\n",
    "    feature_details = feature_handling[col]['feature_details']\n",
    "    # Impute missing values if the key exists\n",
    "    if 'missing_values' in feature_details and feature_details['missing_values'] == 'Impute':\n",
    "        if feature_details['impute_with'] == 'Average of values':\n",
    "            df[col].fillna((df[col].mean()), inplace=True)\n",
    "        elif feature_details['impute_with'] == 'custom':\n",
    "            impute_val = feature_details['impute_value']\n",
    "            df[col].fillna(impute_val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e996d0b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=Ellipsis.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m trained_models \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m---> 27\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     trained_models[\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m] \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Return dictionary of trained models\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:662\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    658\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    660\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 662\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    664\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    667\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X, dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_2d:\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;66;03m# If input is scalar raise error\u001b[39;00m\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 761\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    762\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got scalar array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    763\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    764\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    765\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    766\u001b[0m         )\n\u001b[0;32m    767\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    768\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=Ellipsis.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load JSON file into a dictionary\n",
    "with open('sample.json') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# Extract relevant information from JSON\n",
    "X = ...  # training set\n",
    "y = ...  # target variable\n",
    "\n",
    "# Create list of appropriate models based on prediction_type\n",
    "models = []\n",
    "if json_data[\"design_state_data\"][\"target\"][\"prediction_type\"] == \"Regression\":\n",
    "    models.append(LinearRegression())\n",
    "    models.append(DecisionTreeRegressor())\n",
    "    models.append(RandomForestRegressor())\n",
    "elif json_data[\"design_state_data\"][\"target\"][\"prediction_type\"] == \"Classification\":\n",
    "    # add classification models here if needed\n",
    "    pass\n",
    "\n",
    "# Train each model on the training set and target variable\n",
    "trained_models = {}\n",
    "for model in models:\n",
    "    model.fit(X, y)\n",
    "    trained_models[type(model).__name__] = model\n",
    "\n",
    "# Return dictionary of trained models\n",
    "return trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d248548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['session_info', 'target', 'train', 'metrics', 'feature_handling', 'feature_generation', 'feature_reduction', 'hyperparameters', 'weighting_stratergy', 'probability_calibration', 'algorithms'])\n"
     ]
    }
   ],
   "source": [
    "if 'design_state_data' in data:\n",
    "    # print the keys in the nested dictionary\n",
    "    print(data['design_state_data'].keys())\n",
    "else:\n",
    "    print(\"'design_state_data' not found in JSON data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c82a77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prediction_type': 'Regression',\n",
       " 'target': 'petal_width',\n",
       " 'type': 'regression',\n",
       " 'partitioning': True}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['design_state_data']['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2aac0887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width      species\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load iris dataset into a pandas DataFrame\n",
    "iris_df = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "# Print the first 5 rows of the DataFrame\n",
    "print(iris_df.head())\n",
    "# use one hot encoding in species column\n",
    "#remove outlier\n",
    "#summuarise the data\n",
    "#do EDA\n",
    "#DO CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "798ae26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "\n",
      "   species    0    1    2  \n",
      "0        0  1.0  0.0  0.0  \n",
      "1        0  1.0  0.0  0.0  \n",
      "2        0  1.0  0.0  0.0  \n",
      "3        0  1.0  0.0  0.0  \n",
      "4        0  1.0  0.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Convert the iris dataset into a pandas DataFrame\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df[\"species\"] = iris.target\n",
    "\n",
    "# Apply one hot encoding to the \"species\" column\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "onehot_encoded = onehot_encoder.fit_transform(iris_df[[\"species\"]])\n",
    "\n",
    "# Add the one hot encoded columns to the DataFrame\n",
    "for i, category in enumerate(onehot_encoder.categories_[0]):\n",
    "    iris_df[category] = onehot_encoded[:, i]\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(iris_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bf38f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    0\n",
       "sepal width (cm)     0\n",
       "petal length (cm)    0\n",
       "petal width (cm)     0\n",
       "species              0\n",
       "0                    0\n",
       "1                    0\n",
       "2                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a31e6859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.2\n",
      "1    0.2\n",
      "2    0.2\n",
      "3    0.2\n",
      "4    0.2\n",
      "Name: petal width (cm), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a pandas DataFrame from the iris data and target\n",
    "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "iris_df[\"target\"] = iris.target\n",
    "\n",
    "# Select the \"petal_width\" column\n",
    "petal_width = iris_df[\"petal width (cm)\"]\n",
    "print(petal_width.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84176f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Define X and y\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d472ca",
   "metadata": {},
   "source": [
    "# LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3448209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4baa9a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3d65428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9138644693803301"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc48d81",
   "metadata": {},
   "source": [
    "# SUPPRT VECTOR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "906c50e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.03663251709690416\n",
      "Coefficient of determination (R^2): 0.9427616920360873\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "model = SVR(kernel='rbf', C=100, gamma='auto')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print model performance metrics\n",
    "print(\"Mean squared error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"Coefficient of determination (R^2):\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fab050b",
   "metadata": {},
   "source": [
    "# LASSO REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5228e3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.          0.40782891  0.        ]\n",
      "Mean squared error: 0.06677344873438022\n",
      "Coefficient of determination (R^2): 0.9044577045136054\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the iris dataset\n",
    "iris_df = datasets.load_iris()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Lasso regression model and fit it to the training data\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "\n",
    "# Print the coefficients of the model\n",
    "print(lasso.coef_)\n",
    "\n",
    "# Calculate the mean squared error of the model on the test data\n",
    "mse = mean_squared_error(y_test, lasso.predict(X_test))\n",
    "print(\"Mean squared error:\", mse)\n",
    "print(\"Coefficient of determination (R^2):\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c51746",
   "metadata": {},
   "source": [
    "# RIDGE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9bbecb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11709525 -0.05825264  0.25929034  0.53798793]\n",
      "Mean squared error: 0.0373315560572072\n",
      "Coefficient of determination (R^2): 0.946584418996047\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the iris dataset\n",
    "iris_df = datasets.load_iris()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Ridge regression model and fit it to the training data\n",
    "ridge = Ridge(alpha=0.1)\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "# Print the coefficients of the model\n",
    "print(ridge.coef_)\n",
    "\n",
    "# Calculate the mean squared error of the model on the test data\n",
    "mse = mean_squared_error(y_test, ridge.predict(X_test))\n",
    "print(\"Mean squared error:\", mse)\n",
    "print(\"Coefficient of determination (R^2):\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f9f14a",
   "metadata": {},
   "source": [
    "# DECISION TREE REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01b3fd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.00863265306122449\n",
      "Coefficient of determination (R^2): 0.946584418996047\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the iris dataset\n",
    "iris_df = datasets.load_iris()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a decision tree regression model and fit it to the training data\n",
    "dtr = DecisionTreeRegressor(max_depth=3)\n",
    "dtr.fit(X_train, y_train)\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error of the model on the test data\n",
    "mse = mean_squared_error(y_test, dtr.predict(X_test))\n",
    "print(\"Mean squared error:\", mse)\n",
    "print(\"Coefficient of determination (R^2):\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9011cd",
   "metadata": {},
   "source": [
    "# Applying Gradient Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bab045a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVR': SVR(),\n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Decision Tree': DecisionTreeRegressor()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'Linear Regression': {'fit_intercept': [True, False]},\n",
    "    'SVR': {'kernel': ['linear', 'rbf'], 'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']},\n",
    "    'Lasso': {'alpha': [0.1, 1, 10]},\n",
    "    'Ridge': {'alpha': [0.1, 1, 10]},\n",
    "    'Decision Tree': {'max_depth': [2, 4, 6, 8]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3141e89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "{'fit_intercept': True}\n",
      "0.911792126690884\n",
      "SVR\n",
      "{'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.9435623808594176\n",
      "Lasso\n",
      "{'alpha': 0.1}\n",
      "0.8850549360460958\n",
      "Ridge\n",
      "{'alpha': 1}\n",
      "0.9130347612753779\n",
      "Decision Tree\n",
      "{'max_depth': 6}\n",
      "0.9097046685716252\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    clf = GridSearchCV(model, params[name], cv=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(name)\n",
    "    print(clf.best_params_)\n",
    "    print(clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d87a2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model_using_gridsearchcv(X,y):\n",
    "    algos = {\n",
    "        'linear_regression' : {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {\n",
    "                'normalize': [True, False]\n",
    "            }\n",
    "        },\n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1,2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion' : ['mse','friedman_mse'],\n",
    "                'splitter': ['best','random']\n",
    "            }\n",
    "        },\n",
    "        'Ridge': {\n",
    "            'model': Ridge(),\n",
    "            'params': {\n",
    "                'alpha': [1,2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'SVR': {\n",
    "            'model': {'kernel': ['linear', 'rbf'], 'C': [0.1, 1, 10], 'gamma': ['scale', 'auto']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    for algo_name, config in algos.items():\n",
    "        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n",
    "        gs.fit(X,y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(scores,columns=['model','best_score','best_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41793c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
